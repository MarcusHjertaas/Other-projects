{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1\n",
    "### Published: Monday, Jan. 8, 2024\n",
    "### Deadline: Monday, Jan. 22, 2024\n",
    "\n",
    "Consult the [lab description](lab1_description.md) for background material and suggested reading.\n",
    "\n",
    "Many of these questions will likely feel challenging, as you have not yet been exposed to sufficient background material. They are, however, meant to cover both the curious student and introduce those new to the topics to the world of LLMs.\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "- You must answer at least 10 out of the 21 questions for passing the lab.\n",
    "- Deliver a copy of this notebook on blackboard named `lab1_exercises_{your-username}.ipynb`\n",
    "\n",
    "## Questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. A language model (LM) is...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical models used for predicting word sequences, or find the probability of a word sequence, given context. It is a type of artificial inteligence designed to generate human-like language or responses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. A large language model (LLM) is...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An upscaled version of the language model, often fine-tuned but not nessecarily. It is a model containing more parameters and also often better performance. In general the corpus is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. A pre-trained base/foundation model is...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis for language models, only used to predict a word, but not generate speach. An extremly simple version of a language model used as a building block in more complex models. You could possibly also call GPT 3 a foundation model as it is a large pre-trained LM that can later be finetuned into something like chatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What do we mean by fine-tuned language models, and what does the *head* mean in this context?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning with respect to LM means that a pre-trained model is trained to do more spesific tasks, this could vary in meaning, but picture a model only being able to respond with code, or python code. Or you could train a LLM like GPT on a given book, like a financial book, and feed it companies, yielding results like a financial evaluation of the input company. The head in this context refers to the additional layers or mechanisms added on top of the pre-trained base model to adapt it for specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Which one is more suitable for a chatbot: a pretrained model or a pretrained + fine-tuned model?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general chatbot like ChatGPT should likely only be pre-trained, this way it can respond to more general to questions. Fine tuning would provide better answers in a given field but likely worse overall results. However if the purpose is only to maintain conversation it sounds like fine tuning on conversational data is appropriate, a all purpose model like chatgpt is perhaps less tuned towards conversation.\n",
    "\n",
    "I guess it depends on what the purpose is as, pre trained models have benefits of quick deployment and general understanding while also lacking specificity. Fine-tuned versions are more task specific but also more resource intensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. What do we mean by knowledge cutoff in models like ChatGPT?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge cutoffs for models like ChatGPT refers to its database size, previously the knowledge cutoff for chatGPT was in 2021, while recently it has been updated to 2023. This means newer and relevant data is accessible and can be trained and inform the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. What do we mean when we talk about confabulations/hallucinations of LLMs?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallucinations in LLMs are one of, atleast ChatGPT's, main criticism from the public. It refers to producing gramaticly correct and seemingly sensible answers while them being factually incorrect. This is no issue when prompting for fictional responses. However, when asking factual questions this leads to missinformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. The context length (e.g. 4096) of a GPT-based model is...**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context length is essentialy the number of words or tokens a model can comprehend at once. After this it looses previous context in order to keep up with new information.This means it cannot handle prompts above 4096 words, but also that after the \"conversation\" contains more than 4096 words it will start to loose previous context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Why is it problematic to increase the context/sequence length for transformer-based models?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALthough increasing the context/sequence length enables for a more robust model that can find more complex and better word-combinations. However it also requires more memory and processing power, leading to a more costly model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Parameters are used to describe the model size of LLMs (such as 7B, 13B, â€¦). What do these parameters represent, and what makes LLMs difficult to interpret?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are the features in the model that allows it to understand and generate language. Similar to as in a machine learning model it refers to a variable that contains information about the data. Having a large set of variables makes it difficult for humans to understand how the models function or use these parameters. The models then tend to be more of a black box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Quantization (e.g. through techniques like LoRa, GPTQ, AWQ) is typically used to reduce the size of LLMs allow them to be run on consumer-grade hardware - even laptops! Explain the main idea behind quantization:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization is used to reduce the size of a LLM by representing activations and weights with low precision datatype representation. By reducing the number of bits, from the standard 32 to 8, you acchive a model that requires less memory storage and consumes less energy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. LLMs need vast training data. The size of training data is typically referred to as tokens. What is a token and what happens to unknown words outside of the models' vocabulary?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens are the units used to divide the text. A token can be a word but also a character or a part of a word, it can also be larger structures like scentences. All LLM's have a given vocabulary and if a word is not in that it cannot be outputted, meaning it wont be a response to any prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. What is the difference between model training and model inference?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training refers to the process of learning, where the model is fedd the data and is able to pick up patterns and analyze the data. The model inference refers to the ability to make predicitons about the data or future data and produce a result from this. In essence the training pahase is used in order for the model to learn how to infer something about the data. While in the inference phase this is already known and thefore the model simply draws conclutions based on inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.  Why are GPUs (graphics processing units) ideal for training larger transformer-based models?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs are used in larger transformer based models, aswell some complex ML models, because of its ability to accelerate parallel computations. Meaning the traning process is much faster than using the Core Processing Unit (CPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15.  What is the biggest technical limitation with respect to GPUs for training LLMs?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am somewhat uncertain what the limitations are, but i assume it has something to do with the fact that dispite having a better multitasking ability due to many cores the GPU cores are often weaker. Therfore they are limited in the amount of information they can process in each core. Dealing with large data this could cause issues or be less effective than the more powerful cores in a CPU. Additionally, GPUs have a finite memory, so dealing with long sequences could prove limitating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. LLMs aimed towards human interactions should be *aligned*. What does this mean?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alignment in LLMs refer to the model being \"safe\" to interact to and match what we expect of them. In sorts in means teaching the model to live by human rules and our preferable responses. Not only is this valueable interms of keeping with ethics and such. However it can also make the answers more relateable or useful in interpretations and such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17. RLHF (reinforcement learning from human feedback) is used in models like ChatGPT. While you are not expected to learn about reinforcement learning (RL), explain the following terms in context of LLMs (1 sentence each):**\n",
    "\n",
    "ðŸ”º this question might be too hard without any knowledge of RL. feel free to skip it. ðŸ”º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SFT (supervised fine-tuning)\n",
    "    - your answer\n",
    "- Reward model\n",
    "    - your answer\n",
    "- Policy model\n",
    "    - your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18. For the above procedures, we require data, ideally labeled by humans. This is called data annotation. In this context, what is inter-annotator agreement, and why is it important for model creation?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annontation refers to the process of labeling data. Inter-annotater agreement refers to the degree in which annotators agree with the labeling of data a high degree of inter-annotation means there is a high conncensus for the labels, while a low degree means there are uncertanties tied to the labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19. Do you believe LLM projects should be open-sourced? Why?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM projects should be open source, it is the creators right in many ways to choose this, but allowing insight into how the best and cutting edge models could benefit development further and increase a general understanding of their inner workings. Additionally in the case of faults it could be easier for outsiders to understand why, and the models and their creators could avoid criticism. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20. Why is it important to consider the ethical implications of LLMs?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LLMs grow larger and are more prominent and used in different forms of work the concept of ethics become more important. Using these models for malicious intent or simply creating these to spread missinformation could cause severe problems. Already the prominence of genereated text being precived as facts are becoming a problem, as these models are extreamly good at emulating humans they pose seemingly correct answers only containing no factual sustanance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21. *Smaller* language models ($\\leq 100M$ parameters) will likely be important in the days to come. What are some motivations for smaller models?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller language models have the benefit of possibly being run on a laptop or phone, being more acessible to the common user. While hopefully still being able to produce good results. There is also a large reduction in training costs using these smaller models, which is largly benefical for smaller compainies wanting to develop their own language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "- **What are your expectations for this course? What do you hope to learn?**\n",
    "- **Were the questions too difficult?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect to learn how to build a LM in python and how it functions, i also hope to leave with a better understanding of the LLM-revolution currently happening, what differs between models and how they can be utilised best.\n",
    "I think the questions had a ok level of difficulty."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
