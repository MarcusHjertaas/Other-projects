{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Chunking\n",
    "**1. Create a chunker that detects noun-phrases (NPs) and lists the NPs in the text below.**\n",
    "\n",
    "- Both [NLTK](https://www.nltk.org/book/ch07.html) and [spaCy](https://spacy.io/api/matcher) supports chunking\n",
    "- Look up RegEx parsing for NLTK and the document object for spaCy.\n",
    "- Make use of what you've learned about tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The senteces parsed with the standard pos tagger from nltk.\n",
      "[('The', 'DT'), ('language', 'NN'), ('model', 'NN'), ('predicted', 'VBD'), ('the', 'DT'), ('next', 'JJ'), ('word', 'NN'), ('It', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('very', 'RB'), ('nice', 'JJ'), ('word', 'NN')]\n",
      "\n",
      "The text parsed with pos tagger and chunked with a spesific noun phrase pattern\n",
      "(NP The/DT language/NN model/NN)\n",
      "('predicted', 'VBD')\n",
      "(NP the/DT next/JJ word/NN)\n",
      "('It', 'PRP')\n",
      "('was', 'VBD')\n",
      "(NP a/DT very/RB nice/JJ word/NN)\n"
     ]
    }
   ],
   "source": [
    "text = \"The language model predicted the next word. It was a very nice word!\"\n",
    "# TODO: set up a pos tagger and a chunker.\n",
    "# Output: a list of all tokens, grouped as noun-phrases where applicable\n",
    "\n",
    "from nltk import pos_tag\n",
    "from nltk.chunk.regexp import RegexpParser\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "def pos_tagger(text):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    t_text = tokenizer.tokenize(text)\n",
    "    return pos_tag(t_text)\n",
    "\n",
    "print(\"The senteces parsed with the standard pos tagger from nltk.\")\n",
    "print(pos_tagger(text))\n",
    "\n",
    "patterns = \"\"\"  \n",
    "    NP: {<DT>?<RB>?<JJ>*<NN>+} \n",
    "\n",
    "\"\"\"\n",
    "def regexp_chunker(patterns, text):\n",
    "    PChunker = RegexpParser(patterns)\n",
    "    parsed_text = PChunker.parse(pos_tagger(text))\n",
    "    return parsed_text\n",
    "\n",
    "print()\n",
    "print(\"The text parsed with pos tagger and chunked with a spesific noun phrase pattern\")\n",
    "phrases = regexp_chunker(patterns, text)\n",
    "for phrase in phrases:\n",
    "    print(phrase)\n",
    "# regexp_chunker(patterns, text).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Modify the chunker to handle verb-phases (VPs) as well.**\n",
    "- This can be done by using a RegEx parser in NLTK or using a spaCy Matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text parsed with pos tagger and chunked with a spesific NP and VP pattern\n",
      "(NP The/DT language/NN model/NN)\n",
      "(VP predicted/VBD the/DT next/JJ word/NN)\n",
      "('It', 'PRP')\n",
      "(VP was/VBD a/DT very/RB nice/JJ word/NN)\n"
     ]
    }
   ],
   "source": [
    "# TODO: set up grammars to chunk VPs\n",
    "\n",
    "grammar = \"\"\"\n",
    "    VP: {<VB*.><DT>?<RB>?<JJ>?<NN>}\n",
    "    NP: {<DT>?<RB>?<JJ>*<NN>+}\n",
    "   \n",
    "\"\"\"\n",
    "\n",
    "print(\"The text parsed with pos tagger and chunked with a spesific NP and VP pattern\")\n",
    "for phrase in regexp_chunker(grammar, text):\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Verb-phrases (VPs) can be defined by many different grammatical rules. Give four examples.**\n",
    "- Hint: Context-Free Grammars, chapter 8 in NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verb Phrases usually consist of a verb combined with a different phrase type. Unlike noun phrases its unlikely to see several verbs in a row, but not impossible. From the NLTK documentation there are here four examples of verbs followed by a different phrase type. <br>\n",
    " VP: <br>\n",
    "V Adj <br>\n",
    "V NP <br>\n",
    "V PP<br>\n",
    "V NP PP<br>\n",
    "In the text above i combined the verb phrase with the noun phrases that included prepositions as well as an adjective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. After these applications, do you find chunking to be beneficial in the context of language modeling and next-word prediction? Why or why not?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would assume it to be quite benefical in processes like semantic analysis as the addition of adjectives would likely determine if there is an opinion within the text. Using POS and chuncking with some additional use of n-grams could likely provide the context needed to sort out what these adjectives are desribing and if they contain negations or any sort of hidden meaning, increasing the likelihood of concluding the correct semantic meaning.\n",
    "Additionally the grouping of phrases and the language understanding it can provide would be useful in most language modelling, from classifing text to understanding queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use spaCy to inspect/visualise the dependency tree of the text provided below.**\n",
    "- Optional addition: visualize the dependencies as a graph using `networkx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"971991f45bea4b15940b62d1847b2f19-0\" class=\"displacy\" width=\"1100\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: indianred; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">model</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">predicted</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">next</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">word</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-971991f45bea4b15940b62d1847b2f19-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,177.0 347.0,177.0 347.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-971991f45bea4b15940b62d1847b2f19-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-971991f45bea4b15940b62d1847b2f19-0-1\" stroke-width=\"2px\" d=\"M212,227.0 212,202.0 344.0,202.0 344.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-971991f45bea4b15940b62d1847b2f19-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,229.0 L208,221.0 216,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-971991f45bea4b15940b62d1847b2f19-0-2\" stroke-width=\"2px\" d=\"M362,227.0 362,202.0 494.0,202.0 494.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-971991f45bea4b15940b62d1847b2f19-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,229.0 L358,221.0 366,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-971991f45bea4b15940b62d1847b2f19-0-3\" stroke-width=\"2px\" d=\"M662,227.0 662,177.0 947.0,177.0 947.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-971991f45bea4b15940b62d1847b2f19-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,229.0 L658,221.0 666,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-971991f45bea4b15940b62d1847b2f19-0-4\" stroke-width=\"2px\" d=\"M812,227.0 812,202.0 944.0,202.0 944.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-971991f45bea4b15940b62d1847b2f19-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M812,229.0 L808,221.0 816,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-971991f45bea4b15940b62d1847b2f19-0-5\" stroke-width=\"2px\" d=\"M512,227.0 512,152.0 950.0,152.0 950.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-971991f45bea4b15940b62d1847b2f19-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,229.0 L954.0,221.0 946.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"The language model predicted the next word\"\n",
    "# TODO: use spacy and displacy to visualize the dependency tree\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "document = nlp(text)\n",
    "options = {\"compact\": True, \"color\": \"indianred\"}\n",
    "displacy.render(document, style=\"dep\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is the root of the sentence? Attempt to spot it yourself, but the answer should be done by code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root word in this text is: predicted\n",
      "The POS tag of predicted is: VBD\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement a function to find the root of the document\n",
    "# Return both the word and its POS tag\n",
    "\n",
    "for token in document:\n",
    "    if token.head.text == token.text:\n",
    "        print(\"The root word in this text is:\", token.text)\n",
    "        print(\"The POS tag of\", token.text, \"is:\", token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Find the subject and object of a sentence. Print the results for the sentence above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language model -> model\n",
      "the next word -> word\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement a function to find the subjects + objects in the document\n",
    "\n",
    "def get_subject_chunk(doc) -> str:\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if (\"subj\" in chunk.root.dep_):\n",
    "            return chunk\n",
    "def get_subject(doc) -> str:\n",
    "    for token in doc:\n",
    "        if (\"subj\" in token.dep_):\n",
    "            return token.text\n",
    "\n",
    "def get_object_chunk(doc) -> str:\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if (\"dobj\" in chunk.root.dep_):\n",
    "            return chunk\n",
    "\n",
    "def get_object(doc) -> str:\n",
    "    for token in doc:\n",
    "        if (\"dobj\" in token.dep_):\n",
    "            return token.text\n",
    "\n",
    "print(get_subject_chunk(document),\"->\", get_subject(document))\n",
    "print(get_object_chunk(document),\"->\", get_object(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. How would you use the relationships extracted from dependency parsing in language modeling contexts?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to chuncking, dependency provides an additional context and relative word understanding that should be helpful in most language modelling. Using the example of semantic analysis again, provided you know how the words are dependent on eachother you can understand better how the describing words impact the general message of the sentence or text. This would also be largly usefull in classification, deducing what the general subject of the text is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use Wordnet (from NLTK) and create a function to get all synonyms of a word of your choice. Try with \"language\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'language',\n",
       " 'linguistic_communication',\n",
       " 'linguistic_process',\n",
       " 'lyric',\n",
       " 'nomenclature',\n",
       " 'oral_communication',\n",
       " 'speech',\n",
       " 'speech_communication',\n",
       " 'spoken_communication',\n",
       " 'spoken_language',\n",
       " 'terminology',\n",
       " 'voice_communication',\n",
       " 'words'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "# TODO: find synonyms\n",
    "\n",
    "def get_synonyms(word: str) -> set:\n",
    "    synonyms = set()\n",
    "    [synonyms.update(syn_set.lemma_names()) for syn_set in wn.synsets(word)]\n",
    "    return synonyms\n",
    "\n",
    "get_synonyms(\"language\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. From the same word you chose, extract an additional 4 or more features from wordnet (such as hyponyms). Describe each category briefly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Synonyms': {'dazed',\n",
       "  'dolt',\n",
       "  'dullard',\n",
       "  'pillock',\n",
       "  'poor_fish',\n",
       "  'pudden-head',\n",
       "  'pudding_head',\n",
       "  'stunned',\n",
       "  'stupe',\n",
       "  'stupefied',\n",
       "  'stupid',\n",
       "  'stupid_person',\n",
       "  'unintelligent'},\n",
       " 'Antonyms': {'intelligent', 'smart'},\n",
       " 'Hypernyms': {'simple', 'simpleton'},\n",
       " 'Attributes': {'intelligence'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: expand the function to find more features!\n",
    "\n",
    "def get_antonyms(word: str) -> set:\n",
    "    antonyms = set()\n",
    "    for syn_set in wn.synsets(word):\n",
    "        for lemma in syn_set.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                antonyms.add(antonym.name())\n",
    "    return antonyms\n",
    "\n",
    "def get_hypernyms(word: str) -> set:\n",
    "    hypernyms = set()\n",
    "    for syn_set in wn.synsets(word): \n",
    "        [hypernyms.update(hyp_set.lemma_names()) for hyp_set in syn_set.hypernyms()]\n",
    "    return hypernyms\n",
    "\n",
    "def get_attributes(word: str) -> set:\n",
    "    attributes = set()\n",
    "    for syn_set in wn.synsets(word): \n",
    "        [attributes.update(att_set.lemma_names()) for att_set in syn_set.attributes()]\n",
    "    return attributes\n",
    "\n",
    "def get_word_features(word: str) -> dict:\n",
    "    syn, ant, hyp, att = get_synonyms(word), get_antonyms(word), get_hypernyms(word), get_attributes(word)\n",
    "    features = {\"Synonyms\": syn, \"Antonyms\": ant, \"Hypernyms\": hyp, \"Attributes\": att}\n",
    "    return features\n",
    "\n",
    "get_word_features(\"stupid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Exercise - A sentiment classifier\n",
    "- A rule-based approach with SentiWordNet + A machine learning classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. There are several steps required to build a classifier or any sort of machine learning application for textual data. For data including (INPUT_TEXT, LABEL), list the typical pipeline for classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical machine learning pipline: <br>\n",
    "select relevant data -> Preprocess -> Split to training and testing -> feature extraction -> model creation -> model training -> test and evaluate -> make changes if nessecary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Before developing a classifier, having a baseline is very useful. Build a baseline model for sentiment classification using SentiWordNet.**\n",
    "- How you decide to aggregate sentiment is up to you. Explain your approach.\n",
    "- It should report the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1]\n",
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "\n",
    "# TODO: implement a function to get the sentiment of a text\n",
    "# Must use the sentiwordnet lexicon\n",
    "\n",
    "# Evaluate it on the following sentences:\n",
    "sents = [\n",
    "    \"I liked it! Did you?\",\n",
    "    \"It's not bad but... Nevermind, it is.\",\n",
    "    \"It's awful\",\n",
    "    \"I don't care if you loved it - it was terrible!\",\n",
    "    \"I don't care if you hated it, I think it was awesome\"\n",
    "]\n",
    "# 0: negative, 1: positive\n",
    "y_true = [1, 0, 0, 0, 1]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def word_sentiment_score(word: str) -> float:\n",
    "    synsets = list(swn.senti_synsets(word))\n",
    "    if synsets:\n",
    "        sentiment = synsets[0]\n",
    "        return sentiment.pos_score() - sentiment.neg_score()\n",
    "    else:\n",
    "        return 0.0  \n",
    "\n",
    "def sent_sentiment(sentences: list[str]) -> list[int]:\n",
    "    sentiment_labels = []\n",
    "    for sent in sentences:\n",
    "        sentence = nlp(sent)\n",
    "        sentence_sentiment = sum(word_sentiment_score(token.text) for token in sentence)\n",
    "        sentiment_labels.append(1 if sentence_sentiment >= 0 else 0)  \n",
    "    return sentiment_labels\n",
    "\n",
    "classifications = sent_sentiment(sents)\n",
    "print(classifications)\n",
    "print(\"Score:\", sum(1 for x,y in zip(classifications, y_true) if x == y) / len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this code i decided each word was represented with the difference between their positive and negative scores in the swn library. Then these differences were aggregated in the sum fuction totaling a score for the entire sentence. Wheather or not this sentence was classified as a having a positive or negative sentiment depended wheather their score was positive or negative. <br>\n",
    "This method is quite simple and disregards all negations or other phrasings that provide negative words while eluding to something positive or vice versa. In this case it functions, but for more complex texts it would likely fail to classify the text properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SST-2 binary sentiment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Split the training set into a training and test set. Choose a split size, and justify your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (C:/Users/marcu/.cache/huggingface/datasets/parquet/sst2-1151590ea3b3f98b/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2b9395c29f4b44ae40d20e60944309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    5523\n",
      "0    4477\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64594</th>\n",
       "      <td>there 'll be a power outage during your screen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11796</th>\n",
       "      <td>the color sense of stuart little 2 is its most...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26050</th>\n",
       "      <td>photographed with color and depth , and rather...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57107</th>\n",
       "      <td>too few laughs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28994</th>\n",
       "      <td>its limit to sustain a laugh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "64594  there 'll be a power outage during your screen...      0\n",
       "11796  the color sense of stuart little 2 is its most...      1\n",
       "26050  photographed with color and depth , and rather...      1\n",
       "57107                                    too few laughs       0\n",
       "28994                      its limit to sustain a laugh       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"sst2\")\n",
    "\n",
    "train_df = dataset[\"train\"].to_pandas().drop(columns=[\"idx\"])\n",
    "train_df = train_df.sample(10000)  # a tiny subset\n",
    "print(train_df.label.value_counts())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split the data\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "train_df, test_df = TTS(train_df, train_size=0.8, random_state=42)\n",
    "\n",
    "# I choose an 80/20 split as this is a quite common divider in the ML world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluate your baseline model on the test set.**\n",
    "\n",
    "- Additionally: compare it against a random baseline. That is, a random guess for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.634\n",
      "Random baseline: 0.496\n"
     ]
    }
   ],
   "source": [
    "# TODO: evaluate on test set + random guess\n",
    "# Report results in terms of accuracy\n",
    "import numpy as np\n",
    "predictions = sent_sentiment(test_df[\"sentence\"])\n",
    "print(\"Model score:\", sum(1 for x,y in zip(predictions, test_df[\"label\"]) if x == y) / len(test_df))\n",
    "\n",
    "rand = np.random.choice([0, 1], size=(len(test_df),))\n",
    "print(\"Random baseline:\", sum(1 for x,y in zip(rand, test_df[\"label\"]) if x == y)/ len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Did you beat random guess?**\n",
    "\n",
    "If not, can you think of any reasons why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model did indeed outperform the random baseline. As the score of the baseline is close to 0.5 it could mean that there is about 50/50 of the two classes in the dataset, in this case the split is 55/45, meaning a random model will almost always get scores of around 50% accuracy. Despite my model not being great at 63.4% it still performed better likely due to the fact that it manages to read some words and get classify the postivie and negative words correctly. The error i assume is due to the lack of context for negation and other gramatical tricks that change the sentiment face value for a word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Naive Bayes and TF-IDF\n",
    "This is the final task of the lab. You will use high-level libraries to implement a TF-IDF vectorizer and train your data using a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.64      0.54       671\n",
      "           1       0.78      0.63      0.70      1329\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.62      0.64      0.62      2000\n",
      "weighted avg       0.67      0.63      0.64      2000\n",
      "\n",
      "The Accuracy of the model is:  78.95 %\n"
     ]
    }
   ],
   "source": [
    "# TODO: use scikit-learn to...\n",
    "# - normalize\n",
    "# - vectorize/extract features\n",
    "# - train a classifier\n",
    "# - evaluate the classifier using `classification_report` and `accuracy`\n",
    "# \n",
    "# expect an accuracy of > 0.8\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "\n",
    "def tf_idf_vectorize(train_data, test_data):\n",
    "    vectorizer = TfidfVectorizer(encoding=\"utf-8\", strip_accents=\"ascii\", \n",
    "                                 lowercase=True, analyzer=\"word\", stop_words=\"english\")\n",
    "    \n",
    "    train_vector = vectorizer.fit_transform(train_data)\n",
    "    test_vector = vectorizer.transform(test_data)\n",
    "    return train_vector, test_vector\n",
    "\n",
    "train_vector, test_vector = tf_idf_vectorize(train_df[\"sentence\"], test_df[\"sentence\"])\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(train_vector, train_df[\"label\"])\n",
    "\n",
    "print(\"The classification report:\")\n",
    "print(classification_report(predictions, test_df[\"label\"]))\n",
    "print(\"The Accuracy of the model is:\", accuracy_score(model.predict(test_vector), test_df[\"label\"])*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gridsearch on additional features i was able to improve the score to above 80%, although this was performed in a different notebook. The model also acchived that with its inital randomized train test split, prior to fixing the random_state to 42."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional task: using a pre-trained transformer model\n",
    "If you wish to push the accuracy as far as you can, take a look at BERT-based or other pre-trained language models. As a starting point, take a look at a model already fine-tuned on the SST-2 dataset: [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "\n",
    "**Advanced:**\n",
    "\n",
    "Going beyond this, you could look into the addition of a *classification head* on top of the pooling layer of a BERT-based model. This is a common approach to fine-tuning these models on classification or regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
